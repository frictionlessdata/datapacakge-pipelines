pipeline-test-basic:
  pipeline:
    -
      run: add_metadata
      parameters:
        name: 'al-treasury-spending'
        title: 'Albania Treasury Service'
        granularity: transactional
        countryCode: AL
        homepage: 'http://spending.data.al/en/treasuryservice/list/year/2014/inst_code/1005001'
    -
      run: add_resource
      parameters:
        name: "treasury"
        url: "https://raw.githubusercontent.com/openspending/fiscal-data-package-demos/master/al-treasury-spending/data/treasury.csv"
        schema:
          fields:
            -
              name: "Budget Institution"
              type: string
            -
              name: "Supplier"
              type: string
            -
              name: "Treasury Branch"
              type: string
            -
              name: "Value"
              type: number
            -
              name: "Date registered"
              type: date
            -
              name: "Date executed"
              type: date
            -
              name: "Receipt No"
              type: string
            -
              name: "Kategori Shpenzimi"
              type: string
            -
              name: "Receipt Description"
              type: string
    -
      run: stream_remote_resources
    -
      run: pipeline-test-supplier-titleize
      parameters:
        key: Supplier
    -
      run: ..extract-year
      parameters:
         from-key: "Date executed"
         to-key: "Year"
    -
      run: ..common.pipeline-common
    -
      run: dump.to_zip
      parameters:
          out-file: dump.zip


pipeline-test-big-outputs:
  pipeline:
    - run: big-outputs
    - run: big-outputs


pipeline-test-hooks:
  pipeline:
    -
      run: add_metadata
      parameters:
        name: 'hook-tests'
    -
      run: add_resource
      parameters:
        name: "treasury"
        url: "https://raw.githubusercontent.com/openspending/fiscal-data-package-demos/master/al-treasury-spending/data/treasury.csv"
    -
      run: dump.to_path
      parameters:
          out-path: hooks-outputs

  hooks:
    - http://localhost:9000/update

pipeline-test-datatypes:
  pipeline:
    -
      run: add_metadata
      parameters:
        name: 'type-tests'
    -
      run: add_resource
      parameters:
        name: types
        url: types.csv
    -
      run: stream_remote_resources
    -
      run: set_types
      parameters:
        types:
          string:
            type: string
          number:
            type: number
          integer:
            type: integer
          boolean:
            type: boolean
          object:
            type: object
          array:
            type: array
          date:
            type: date
          datetime:
            type: datetime
          time:
            type: time
          year:
            type: year
          yearmonth:
            type: yearmonth
          duration:
            type: duration
          geopoint:
            type: geopoint
          geojson:
            type: geojson
    -
      run: dump.to_path
      parameters:
          out-path: type-tests-output

pipeline-test-datatypes2:
  dependencies:
    - pipeline: ./tests/env/dummy/pipeline-test-datatypes
  pipeline:
    -
      run: add_metadata
      parameters:
        name: 'type-tests'
    -
      run: load_resource
      parameters:        
        url: dependency://./tests/env/dummy/pipeline-test-datatypes
        resource: types
    -
      run: dump.to_path
      parameters:
          out-path: type-tests-output2

pipeline-test-code:
  dependencies:
    - pipeline: ./tests/env/dummy/pipeline-test-datatypes
  pipeline:
  -
      run: load_resource
      parameters:
        url: dependency://./tests/env/dummy/pipeline-test-datatypes
        resource: types
  -
    run: code
    code: |
      from datapackage_pipelines.wrapper import ingest, spew
      parameters, datapackage, resources, stats = ingest() + ({},)
      def get_resource():
        for descriptor, resource in zip(datapackage["resources"], resources):
          for row in resource:
            yield row
      spew(datapackage, [get_resource()], stats)
  -
    run: dump.to_path
    parameters:
      out-path: code-test-output


pipeline-test-invalid-remote-datapackage-zip:
  pipeline:
    -
      run: load_resource
      parameters:
        url: https://storage.googleapis.com/knesset-data-pipelines/external-data/maya_full_feb25_18.zip
        resource: .*
    -
      run: code
      code: |
        from datapackage_pipelines.wrapper import ingest, spew
        parameters, datapackage, resources, stats = ingest() + ({},)
        resource_names = [descriptor["name"] for descriptor in datapackage["resources"]]
        def get_row(resource_name, row):
          row.update(**{"_": row[""], "year": resource_name})
          del row[""]; return row
        def get_resource():
          for resource_name, resource in zip(resource_names, resources):
              yield from (get_row(resource_name, row) for row in resource)
        datapackage = dict(datapackage, resources=[datapackage["resources"][0]])
        datapackage["resources"][0].update(name='maya', path='maya.csv')
        for field in datapackage["resources"][0]["schema"]["fields"]:
          if field["name"] == "":
            field["name"] = "_"
        datapackage["resources"][0]["schema"]["fields"].append({"name": "year", "type": "string"})
        spew(datapackage, (get_resource(),), stats)
    -
      run: dump.to_path
      parameters:
        out-path: invalid-remote-datapackage-zip-output
